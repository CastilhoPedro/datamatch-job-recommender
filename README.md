# DataMatch ğŸ“Š

![Status](https://img.shields.io/badge/status-em%20planejamento-yellow)

Um motor de busca focado em competÃªncias para vagas na Ã¡rea de dados, que conecta as habilidades dos profissionais Ã s reais exigÃªncias do mercado.

## ğŸ¯ Objetivo

O objetivo principal do DataMatch Ã© esclarecer o caminho para profissionais que se sentem perdidos no mercado de dados, ajudando-os a identificar onde suas habilidades se encaixam melhor e quais vagas sÃ£o mais adequadas ao seu perfil e nÃ­vel tÃ©cnico. Para isso, o projeto se propÃµe a desenvolver um motor de busca especializado que conecta profissionais a oportunidades de emprego com base em suas competÃªncias tÃ©cnicas, e nÃ£o apenas em tÃ­tulos de vagas.

A motivaÃ§Ã£o surgiu da dificuldade enfrentada por estudantes e profissionais da Ã¡rea, que frequentemente encontram inconsistÃªncias entre os tÃ­tulos das vagas e as habilidades que sÃ£o, de fato, exigidas.

## âœ¨ Funcionalidades Planejadas

* **Busca por Habilidades:** O usuÃ¡rio insere suas competÃªncias tÃ©cnicas (ex: "Python", "Spark", "dashboards") e o sistema busca vagas compatÃ­veis.
* **Matching Inteligente:** Um algoritmo baseado em TF-IDF e Similaridade de Cosseno ranquearÃ¡ as vagas, priorizando a relevÃ¢ncia das habilidades inseridas pelo usuÃ¡rio na descriÃ§Ã£o da vaga.
* **Web Scraping ContÃ­nuo:** O sistema coletarÃ¡ vagas de forma automatizada das principais plataformas (LinkedIn, Glassdoor, Catho) para manter a base de dados sempre atualizada.
* **Interface Intuitiva:** Uma interface simples, desenvolvida com Streamlit, permitirÃ¡ que o usuÃ¡rio filtre os resultados por nÃ­vel de senioridade e data de publicaÃ§Ã£o.
* **Sistema de Feedback:** Um mecanismo de "Like" e "Dislike" serÃ¡ implementado para coletar feedback do usuÃ¡rio e, futuramente, aprimorar a precisÃ£o das recomendaÃ§Ãµes.

## ğŸ› ï¸ Tecnologias

A arquitetura do projeto integra diversas ferramentas e conceitos da engenharia e ciÃªncia de dados:

| Categoria             | Ferramentas e Conceitos                                     |
| :-------------------- | :---------------------------------------------------------- |
| **Coleta de Dados** | Scrapy, BeautifulSoup, Selenium                               |
| **Processamento e NLP** | Scikit-learn, Spacy                                       |
| **Banco de Dados** | PostgreSQL                                                     |
| **Interface (Frontend)**| Streamlit                                                 |
| **Conceitos Base** | Web Scraping, Processamento de Linguagem Natural (NLP), Sistemas de RecomendaÃ§Ã£o |

## ğŸš€ Como Executar o Projeto

>  **AtenÃ§Ã£o:** O projeto ainda estÃ¡ em fase de planejamento. As instruÃ§Ãµes detalhadas de instalaÃ§Ã£o e execuÃ§Ã£o serÃ£o disponibilizadas futuramente.

## ğŸ“ Estrutura do Projeto

A estrutura de diretÃ³rios planejada para organizar o cÃ³digo e os artefatos do projeto Ã© a seguinte:

```
datamatch-job-recommender
â”œâ”€ notebooks
â”‚  â”œâ”€ 01_NLP_development.ipynb
â”‚  â””â”€ 02_Scraper_development.ipynb
â”œâ”€ README.md
â”œâ”€ requirements.txt
â””â”€ src
   â”œâ”€ backend
   â”‚  â”œâ”€ config
   â”‚  â”‚  â”œâ”€ settings.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ database
   â”‚  â”‚  â”œâ”€ connection.py
   â”‚  â”‚  â”œâ”€ database.py
   â”‚  â”‚  â”œâ”€ models.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ processing
   â”‚  â”‚  â”œâ”€ nlp.py
   â”‚  â”‚  â”œâ”€ utils
   â”‚  â”‚  â”‚  â”œâ”€ model_persistence.py
   â”‚  â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”‚  â”œâ”€ vectorizer.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ scrapers
   â”‚  â”‚  â”œâ”€ common.py
   â”‚  â”‚  â”œâ”€ glassdoor.py
   â”‚  â”‚  â”œâ”€ linkedin.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ services
   â”‚  â”‚  â”œâ”€ handler_front.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ utils
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â””â”€ __init__.py
   â”œâ”€ frontend
   â”‚  â”œâ”€ app
   â”‚  â”‚  â”œâ”€ main.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â”œâ”€ utils
   â”‚  â”‚  â”œâ”€ commom.py
   â”‚  â”‚  â””â”€ __init__.py
   â”‚  â””â”€ __init__.py
   â”œâ”€ utils
   â”‚  â”œâ”€ helper.py
   â”‚  â””â”€ __init__.py
   â””â”€ __init__.py

```


## ğŸ›£ï¸ PrÃ³ximos Passos (Roadmap)

Embora o algoritmo inicial seja baseado em TF-IDF, o plano de longo prazo inclui aprimoramentos significativos:

* **MigraÃ§Ã£o para Modelos Contextuais:** Evoluir o algoritmo de matching para modelos de linguagem mais avanÃ§ados, como o BERT, para capturar melhor o contexto e a semÃ¢ntica das descriÃ§Ãµes das vagas.
* **PersonalizaÃ§Ã£o com Feedback:** Utilizar os dados de feedback (Likes/Dislikes) para treinar um modelo de recomendaÃ§Ã£o mais personalizado.
* **OtimizaÃ§Ã£o de Performance:** Implementar tÃ©cnicas de indexaÃ§Ã£o para garantir que o sistema continue performÃ¡tico Ã  medida que a base de vagas crescer.


