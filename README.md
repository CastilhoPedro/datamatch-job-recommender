# DataMatch üìä

![Status](https://img.shields.io/badge/status-em%20planejamento-yellow)

Um motor de busca focado em compet√™ncias para vagas na √°rea de dados, que conecta as habilidades dos profissionais √†s reais exig√™ncias do mercado.

## üéØ Objetivo

O objetivo principal do DataMatch √© esclarecer o caminho para profissionais que se sentem perdidos no mercado de dados, ajudando-os a identificar onde suas habilidades se encaixam melhor e quais vagas s√£o mais adequadas ao seu perfil e n√≠vel t√©cnico. Para isso, o projeto se prop√µe a desenvolver um motor de busca especializado que conecta profissionais a oportunidades de emprego com base em suas compet√™ncias t√©cnicas, e n√£o apenas em t√≠tulos de vagas.

A motiva√ß√£o surgiu da dificuldade enfrentada por estudantes e profissionais da √°rea, que frequentemente encontram inconsist√™ncias entre os t√≠tulos das vagas e as habilidades que s√£o, de fato, exigidas.

## ‚ú® Funcionalidades Planejadas

* **Busca por Habilidades:** O usu√°rio insere suas compet√™ncias t√©cnicas (ex: "Python", "Spark", "dashboards") e o sistema busca vagas compat√≠veis.
* **Matching Inteligente:** Um algoritmo baseado em TF-IDF e Similaridade de Cosseno ranquear√° as vagas, priorizando a relev√¢ncia das habilidades inseridas pelo usu√°rio na descri√ß√£o da vaga.
* **Web Scraping Cont√≠nuo:** O sistema coletar√° vagas de forma automatizada das principais plataformas (LinkedIn, Glassdoor, Catho) para manter a base de dados sempre atualizada.
* **Interface Intuitiva:** Uma interface simples, desenvolvida com Streamlit, permitir√° que o usu√°rio filtre os resultados por n√≠vel de senioridade e data de publica√ß√£o.
* **Sistema de Feedback:** Um mecanismo de "Like" e "Dislike" ser√° implementado para coletar feedback do usu√°rio e, futuramente, aprimorar a precis√£o das recomenda√ß√µes.

## üõ†Ô∏è Tecnologias

A arquitetura do projeto integra diversas ferramentas e conceitos da engenharia e ci√™ncia de dados:

| Categoria             | Ferramentas e Conceitos                                     |
| :-------------------- | :---------------------------------------------------------- |
| **Coleta de Dados** | Python (Scrapy, BeautifulSoup, Selenium) |
| **Processamento e NLP** | Scikit-learn (TF-IDF, Similaridade de Cosseno)            |
| **Banco de Dados** | MySQL                                                      |
| **Interface (Frontend)**| Streamlit                                                |
| **Conceitos Base** | Web Scraping, Processamento de Linguagem Natural (NLP), Sistemas de Recomenda√ß√£o |

## üöÄ Como Executar o Projeto

>  **Aten√ß√£o:** O projeto ainda est√° em fase de planejamento. As instru√ß√µes detalhadas de instala√ß√£o e execu√ß√£o ser√£o disponibilizadas futuramente.

## üìÅ Estrutura do Projeto

A estrutura de diret√≥rios planejada para organizar o c√≥digo e os artefatos do projeto √© a seguinte:
```
/datamatch
|
|-- /scrapers           
|-- /app                
|-- /notebooks          
|-- requirements.txt    
|-- ...
```


## üõ£Ô∏è Pr√≥ximos Passos (Roadmap)

Embora o algoritmo inicial seja baseado em TF-IDF, o plano de longo prazo inclui aprimoramentos significativos:

* **Migra√ß√£o para Modelos Contextuais:** Evoluir o algoritmo de matching para modelos de linguagem mais avan√ßados, como o BERT, para capturar melhor o contexto e a sem√¢ntica das descri√ß√µes das vagas.
* **Personaliza√ß√£o com Feedback:** Utilizar os dados de feedback (Likes/Dislikes) para treinar um modelo de recomenda√ß√£o mais personalizado.
* **Otimiza√ß√£o de Performance:** Implementar t√©cnicas de indexa√ß√£o para garantir que o sistema continue perform√°tico √† medida que a base de vagas crescer.
