{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN2orzSqF-iF"
      },
      "source": [
        "# Natural Language Processing with Python\n",
        "\n",
        "<br>\n",
        "\n",
        "Neste notebook ser√° constru√≠do o algoritmo para o m√≥dulo de NLP do DataMatch, aquele usar√° como base o livro Natural Language Processing with Python. (Cap√≠tulos 3, 5, 6)\n",
        "\n",
        "- No cap√≠tulo 3 aprenderemos sobre o processamento do texto;\n",
        "\n",
        "- No 5 aprenderemos o Part-of-Speech (POS) tagging, para saber o que ele identifica como substantivo, adjetivo, e etc. <- √∫til para, por exemplo, filtrarmos apenas os substantivos: Python, SQL, etc.\n",
        "\n",
        "- No cap 6...\n",
        "\n",
        "Link do livro: https://tjzhifei.github.io/resources/NLTK.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywp-N_EAGjdx"
      },
      "source": [
        "## Cap√≠tulo 3\n",
        "\n",
        "Anota√ß√µes Importantes:\n",
        "-\n",
        "- **Tokeniza√ß√£o:** √â o processo de quebrar um texto em v√°rios tokens, ou seja, v√°rias palavras separadas. Ex: \"Eu gosto de NLP.\" -> ['Eu', 'gosto', 'de', 'NLP', '.']\n",
        "\n",
        "\n",
        "- **Normaliza√ß√£o:** primeira coisa ser√° transformar tudo em lowercase, para isso, usaremos o lower() do Python, al√©m disso teremos:\n",
        "\n",
        "  - Stematiza√ß√£o: o Stem de uma palavra √© a sua ra√≠z l√©xica. Ex: andando -> anda. Ent√£o stematizar √© cortar o sulfixo da palavra para que, por exemplo, a palavra \"Requisito\" e \"Requisitos\" se tornem a mesma coisa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMlmzU3MF2-q",
        "outputId": "f056b305-18ea-442c-f8b9-842776ea324a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "import nltk, re\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "!pip install -q spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx58gA3nG-9S",
        "outputId": "7d176a3b-2a41-44b2-c7c6-3ea844f7640a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', '√©', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'solu√ß√µes', 'log√≠sticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inova√ß√µes', 'tecnol√≥gicas', 'configur√°veis', 'que', 'fornecem', 'um', 'fluxo', 'cont√≠nuo', 'de', 'informa√ß√µes', 'e', 'd√£o', '√†', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relat√≥rios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'an√°lises', ',', 'valida√ß√µes', 'e', 'tratamento', 'de', 'inconsist√™ncias', 'nos', 'dados', '.', 'Elaborar', 'relat√≥rios', 'gerenciais', 'para', 'decis√µes', 't√°ticas', 'e', 'estrat√©gicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padroniza√ß√£o', 'e', 'governan√ßa', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'm√©tricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', '√°reas', 'na', 'interpreta√ß√£o', 'de', 'dados', 'e', 'gera√ß√£o', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relat√≥rios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automa√ß√£o', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipula√ß√£o', 'e', 'integra√ß√£o', 'de', 'dados', ')', 'DAX', '(', 'cria√ß√£o', 'de', 'medidas', 'e', 'c√°lculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automa√ß√£o', 'e', 'an√°lise', 'de', 'dados', ')', 'Excel', 'avan√ßado', '(', 'f√≥rmulas', ',', 'tabelas', 'din√¢micas', ',', 'gr√°ficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estrutura√ß√£o', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extra√ß√£o', ',', 'transforma√ß√£o', 'e', 'carga', ')', 'Governan√ßa', 'e', 'qualidade', 'de', 'dados', 'BENEF√çCIOS', 'AOS', 'COLABORADORES', 'ü©∫', 'Seguro', 'Sa√∫de', 'üçΩÔ∏è', 'Vale-Alimenta√ß√£o', 'e', 'Refei√ß√£o', 'na', 'modalidade', 'flex', ',', 'em', 'um', '√∫nico', 'cart√£o', '.', 'üöå', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', 'üèãüèΩüí™üèºüéß', 'Total', 'Pass', '‚Äì', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'sa√∫de', 'e', 'bem-estar', ',', 'como', 'academias', ',', 'est√∫dios', ',', 'escolas', 'de', 'dan√ßa', 'etc', '.', 'üß†üíûüí≠C4Life', '‚Äì', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orienta√ß√µes', 'e/ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicol√≥gico', ',', 'Jur√≠dico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', 'ùöøüçé', 'Clude', '-', 'oferece', 'solu√ß√µes', 'digitais', 'para', 'a', 'sa√∫de', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Sa√∫de', 'do', 'Corpo_Telemedicina', '.', 'Sa√∫de', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutri√ß√£o', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta-feira', '|', 'Hor√°rio', 'padr√£o', ':', '8h30', '√†s', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'S√£o', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "raw = \"SOBRE A EMPRESA Superar expectativas √© o que nos motiva! Fornecemos solu√ß√µes log√≠sticas completas, liderando o setor com inova√ß√µes tecnol√≥gicas configur√°veis que fornecem um fluxo cont√≠nuo de informa√ß√µes e d√£o √† nossa crescente base de clientes uma verdadeira visibilidade da cadeia de suprimentos.  Vem trabalhar com a gente!  (Empresa) Lovers‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ PRINCIPAIS ATIVIDADES Criar, manter e dar suporte a projetos de BI. Desenvolver e atualizar dashboards e relat√≥rios em Power BI e Excel. Realizar an√°lises, valida√ß√µes e tratamento de inconsist√™ncias nos dados. Elaborar relat√≥rios gerenciais para decis√µes t√°ticas e estrat√©gicas. Integrar e mesclar dados de diferentes plataformas, bancos e ferramentas. Garantir a qualidade, padroniza√ß√£o e governan√ßa dos dados. Automatizar processos e fluxos com Power Automate e Python. Criar e otimizar indicadores e m√©tricas em SQL e DAX. Apoiar gestores e √°reas na interpreta√ß√£o de dados e gera√ß√£o de insights. REQUISITOS Power BI (modelagem, dashboards e relat√≥rios) Power Automate (fluxos de automa√ß√£o) SQL e SQL Server (consultas, manipula√ß√£o e integra√ß√£o de dados) DAX (cria√ß√£o de medidas e c√°lculos no Power BI) Python (tratamento, automa√ß√£o e an√°lise de dados) Excel avan√ßado (f√≥rmulas, tabelas din√¢micas, gr√°ficos) DIFERENCIAIS Modelagem e estrutura√ß√£o de banco de dados Processos de ETL (extra√ß√£o, transforma√ß√£o e carga) Governan√ßa e qualidade de dados BENEF√çCIOS AOS COLABORADORES ü©∫ Seguro Sa√∫de üçΩÔ∏è Vale-Alimenta√ß√£o e Refei√ß√£o na modalidade flex, em um √∫nico cart√£o. üöå Vale-Transporte COMBO BEM-ESTAR: üèãüèΩüí™üèºüéß Total Pass ‚Äì conecta o colaborador com parceiros de sa√∫de e bem-estar, como academias, est√∫dios, escolas de dan√ßa etc. üß†üíûüí≠C4Life ‚Äì presta suporte aos colaboradores e dependentes, com orienta√ß√µes e/ou suporte emocional, noss pilares: Psicol√≥gico, Jur√≠dico, Financeiro, Social e Pets. ùöøüçé Clude - oferece solu√ß√µes digitais para a sa√∫de do corpo da mente dos colaboradores. Sa√∫de do Corpo_Telemedicina. Sa√∫de da Mente_ Telepsicologia. Nutri√ß√£o. Jornada de trabalho: Segunda a sexta-feira | Hor√°rio padr√£o: 8h30 √†s 17h30 Modalidade de trabalho: presencial, com 1 dia flex - home office  Local: Faria Lima - S√£o Paulo\"\n",
        "\n",
        "tokens = nltk.word_tokenize(raw) # tokenizador padr√£o.\n",
        "text = nltk.Text(tokens) # conceito mais avan√ßado, √∫til para an√°lises explorat√≥rias.\n",
        "\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SamP4fCGzgYH",
        "outputId": "1a8be251-8ca5-4859-ebe5-6e4d2390f31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', '√©', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'solu√ß√µes', 'log√≠sticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inova√ß√µes', 'tecnol√≥gicas', 'configur√°veis', 'que', 'fornecem', 'um', 'fluxo', 'cont√≠nuo', 'de', 'informa√ß√µes', 'e', 'd√£o', '√†', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers', '‚ù§', 'Ô∏è', 'üö¢', '‚úà', 'Ô∏è', 'üöõ', 'üíº', 'üìà', 'üéØ', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relat√≥rios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'an√°lises', ',', 'valida√ß√µes', 'e', 'tratamento', 'de', 'inconsist√™ncias', 'nos', 'dados', '.', 'Elaborar', 'relat√≥rios', 'gerenciais', 'para', 'decis√µes', 't√°ticas', 'e', 'estrat√©gicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padroniza√ß√£o', 'e', 'governan√ßa', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'm√©tricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', '√°reas', 'na', 'interpreta√ß√£o', 'de', 'dados', 'e', 'gera√ß√£o', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relat√≥rios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automa√ß√£o', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipula√ß√£o', 'e', 'integra√ß√£o', 'de', 'dados', ')', 'DAX', '(', 'cria√ß√£o', 'de', 'medidas', 'e', 'c√°lculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automa√ß√£o', 'e', 'an√°lise', 'de', 'dados', ')', 'Excel', 'avan√ßado', '(', 'f√≥rmulas', ',', 'tabelas', 'din√¢micas', ',', 'gr√°ficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estrutura√ß√£o', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extra√ß√£o', ',', 'transforma√ß√£o', 'e', 'carga', ')', 'Governan√ßa', 'e', 'qualidade', 'de', 'dados', 'BENEF√çCIOS', 'AOS', 'COLABORADORES', 'ü©∫', 'Seguro', 'Sa√∫de', 'üçΩ', 'Ô∏è', 'Vale-Alimenta√ß√£o', 'e', 'Refei√ß√£o', 'na', 'modalidade', 'flex', ',', 'em', 'um', '√∫nico', 'cart√£o', '.', 'üöå', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', 'üèã', 'üèΩ', 'üí™', 'üèº', 'üéß', 'Total', 'Pass', '‚Äì', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'sa√∫de', 'e', 'bem-estar', ',', 'como', 'academias', ',', 'est√∫dios', ',', 'escolas', 'de', 'dan√ßa', 'etc', '.', 'üß†', 'üíû', 'üí≠C4Life', '‚Äì', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orienta√ß√µes', 'e', '/ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicol√≥gico', ',', 'Jur√≠dico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', 'ùöø', 'üçé', 'Clude', '-', 'oferece', 'solu√ß√µes', 'digitais', 'para', 'a', 'sa√∫de', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Sa√∫de', 'do', 'Corpo_Telemedicina', '.', 'Sa√∫de', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutri√ß√£o', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta-feira', '|', 'Hor√°rio', 'padr√£o', ':', '8h30', '√†s', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'S√£o', 'Paulo']\n",
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', '√©', 'o', 'que', 'nos', 'motiva', 'Fornecemos', 'solu√ß√µes', 'log√≠sticas', 'completas', 'liderando', 'o', 'setor', 'com', 'inova√ß√µes', 'tecnol√≥gicas', 'configur√°veis', 'que', 'fornecem', 'um', 'fluxo', 'cont√≠nuo', 'de', 'informa√ß√µes', 'e', 'd√£o', '√†', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', 'Vem', 'trabalhar', 'com', 'a', 'gente', 'Empresa', 'Lovers', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relat√≥rios', 'em', 'Power', 'BI', 'e', 'Excel', 'Realizar', 'an√°lises', 'valida√ß√µes', 'e', 'tratamento', 'de', 'inconsist√™ncias', 'nos', 'dados', 'Elaborar', 'relat√≥rios', 'gerenciais', 'para', 'decis√µes', 't√°ticas', 'e', 'estrat√©gicas', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', 'bancos', 'e', 'ferramentas', 'Garantir', 'a', 'qualidade', 'padroniza√ß√£o', 'e', 'governan√ßa', 'dos', 'dados', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'm√©tricas', 'em', 'SQL', 'e', 'DAX', 'Apoiar', 'gestores', 'e', '√°reas', 'na', 'interpreta√ß√£o', 'de', 'dados', 'e', 'gera√ß√£o', 'de', 'insights', 'REQUISITOS', 'Power', 'BI', 'modelagem', 'dashboards', 'e', 'relat√≥rios', 'Power', 'Automate', 'fluxos', 'de', 'automa√ß√£o', 'SQL', 'e', 'SQL', 'Server', 'consultas', 'manipula√ß√£o', 'e', 'integra√ß√£o', 'de', 'dados', 'DAX', 'cria√ß√£o', 'de', 'medidas', 'e', 'c√°lculos', 'no', 'Power', 'BI', 'Python', 'tratamento', 'automa√ß√£o', 'e', 'an√°lise', 'de', 'dados', 'Excel', 'avan√ßado', 'f√≥rmulas', 'tabelas', 'din√¢micas', 'gr√°ficos', 'DIFERENCIAIS', 'Modelagem', 'e', 'estrutura√ß√£o', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', 'extra√ß√£o', 'transforma√ß√£o', 'e', 'carga', 'Governan√ßa', 'e', 'qualidade', 'de', 'dados', 'BENEF√çCIOS', 'AOS', 'COLABORADORES', 'Seguro', 'Sa√∫de', 'Vale', 'Alimenta√ß√£o', 'e', 'Refei√ß√£o', 'na', 'modalidade', 'flex', 'em', 'um', '√∫nico', 'cart√£o', 'Vale', 'Transporte', 'COMBO', 'BEM', 'ESTAR', 'Total', 'Pass', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'sa√∫de', 'e', 'bem', 'estar', 'como', 'academias', 'est√∫dios', 'escolas', 'de', 'dan√ßa', 'etc', 'C4Life', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', 'com', 'orienta√ß√µes', 'e', 'ou', 'suporte', 'emocional', 'noss', 'pilares', 'Psicol√≥gico', 'Jur√≠dico', 'Financeiro', 'Social', 'e', 'Pets', 'ùöø', 'Clude', 'oferece', 'solu√ß√µes', 'digitais', 'para', 'a', 'sa√∫de', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', 'Sa√∫de', 'do', 'Corpo_Telemedicina', 'Sa√∫de', 'da', 'Mente_', 'Telepsicologia', 'Nutri√ß√£o', 'Jornada', 'de', 'trabalho', 'Segunda', 'a', 'sexta', 'feira', 'Hor√°rio', 'padr√£o', '8h30', '√†s', '17h30', 'Modalidade', 'de', 'trabalho', 'presencial', 'com', '1', 'dia', 'flex', 'home', 'office', 'Local', 'Faria', 'Lima', 'S√£o', 'Paulo']\n",
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', '√©', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'solu√ß√µes', 'log√≠sticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inova√ß√µes', 'tecnol√≥gicas', 'configur√°veis', 'que', 'fornecem', 'um', 'fluxo', 'cont√≠nuo', 'de', 'informa√ß√µes', 'e', 'd√£o', '√†', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers', '‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relat√≥rios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'an√°lises', ',', 'valida√ß√µes', 'e', 'tratamento', 'de', 'inconsist√™ncias', 'nos', 'dados', '.', 'Elaborar', 'relat√≥rios', 'gerenciais', 'para', 'decis√µes', 't√°ticas', 'e', 'estrat√©gicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padroniza√ß√£o', 'e', 'governan√ßa', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'm√©tricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', '√°reas', 'na', 'interpreta√ß√£o', 'de', 'dados', 'e', 'gera√ß√£o', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relat√≥rios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automa√ß√£o', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipula√ß√£o', 'e', 'integra√ß√£o', 'de', 'dados', ')', 'DAX', '(', 'cria√ß√£o', 'de', 'medidas', 'e', 'c√°lculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automa√ß√£o', 'e', 'an√°lise', 'de', 'dados', ')', 'Excel', 'avan√ßado', '(', 'f√≥rmulas', ',', 'tabelas', 'din√¢micas', ',', 'gr√°ficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estrutura√ß√£o', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extra√ß√£o', ',', 'transforma√ß√£o', 'e', 'carga', ')', 'Governan√ßa', 'e', 'qualidade', 'de', 'dados', 'BENEF√çCIOS', 'AOS', 'COLABORADORES', 'ü©∫', 'Seguro', 'Sa√∫de', 'üçΩÔ∏è', 'Vale', '-', 'Alimenta√ß√£o', 'e', 'Refei√ß√£o', 'na', 'modalidade', 'flex', ',', 'em', 'um', '√∫nico', 'cart√£o', '.', 'üöå', 'Vale', '-', 'Transporte', 'COMBO', 'BEM', '-', 'ESTAR', ':', 'üèãüèΩüí™üèºüéß', 'Total', 'Pass', '‚Äì', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'sa√∫de', 'e', 'bem', '-', 'estar', ',', 'como', 'academias', ',', 'est√∫dios', ',', 'escolas', 'de', 'dan√ßa', 'etc', '.', 'üß†üíûüí≠', 'C4Life', '‚Äì', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orienta√ß√µes', 'e', '/', 'ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicol√≥gico', ',', 'Jur√≠dico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', 'ùöø', 'üçé', 'Clude', '-', 'oferece', 'solu√ß√µes', 'digitais', 'para', 'a', 'sa√∫de', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Sa√∫de', 'do', 'Corpo_Telemedicina', '.', 'Sa√∫de', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutri√ß√£o', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta', '-', 'feira', '|', 'Hor√°rio', 'padr√£o', ':', '8h30', '√†s', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'S√£o', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "# Outras formas de tokenizar\n",
        "teste = re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw)\n",
        "print(teste)\n",
        "teste = re.split(r'\\W+', raw)\n",
        "print(teste)\n",
        "teste = nltk.regexp_tokenize(raw, pattern=r\"\\w+(?:'\\w+)?|[^\\w\\s]+\")\n",
        "print(teste)\n",
        "\n",
        "# Outro exemplo abaixo:\n",
        "\n",
        "# text = 'That U.S.A. poster-print costs $12.40...'\n",
        "# pattern = r'(?x)'\n",
        "# ... ([A-Z]\\.)+ # abbreviations, e.g. U.S.A.\n",
        "# ... | \\w+(-\\w+)* # words with optional internal hyphens\n",
        "# ... | \\$?\\d+(\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
        "# ... | \\.\\.\\. # ellipsis\n",
        "# ... | [][.,;\"'?():-_`] # these are separate tokens\n",
        "# nltk.regexp_tokenize(text, pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRZR8mvEOEiA",
        "outputId": "f4bf9566-0f98-400d-e8ea-d4574fdcbd8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming:  ['sobr', 'a', 'empresa', 'superar', 'expectativa', '√©', 'o', 'que', 'no', 'motiva', '!', 'fornecemo', 'solu√ß√µ', 'log√≠stica', 'completa', ',', 'liderando', 'o', 'setor', 'com', 'inova√ß√µ', 'tecnol√≥gica', 'configur√°vei', 'que', 'fornecem', 'um', 'fluxo', 'cont√≠nuo', 'de', 'informa√ß√µ', 'e', 'd√£o', '√†', 'nossa', 'crescent', 'base', 'de', 'client', 'uma', 'verdadeira', 'visibilidad', 'da', 'cadeia', 'de', 'suprimento', '.', 'vem', 'trabalhar', 'com', 'a', 'gent', '!', '(', 'empresa', ')', 'lovers‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ', 'principai', 'atividad', 'criar', ',', 'manter', 'e', 'dar', 'suport', 'a', 'projeto', 'de', 'bi', '.', 'desenvolv', 'e', 'atualizar', 'dashboard', 'e', 'relat√≥rio', 'em', 'power', 'bi', 'e', 'excel', '.', 'realizar', 'an√°lis', ',', 'valida√ß√µ', 'e', 'tratamento', 'de', 'inconsist√™ncia', 'no', 'dado', '.', 'elaborar', 'relat√≥rio', 'gerenciai', 'para', 'decis√µ', 't√°tica', 'e', 'estrat√©gica', '.', 'integrar', 'e', 'mesclar', 'dado', 'de', 'diferent', 'plataforma', ',', 'banco', 'e', 'ferramenta', '.', 'garantir', 'a', 'qualidad', ',', 'padroniza√ß√£o', 'e', 'governan√ßa', 'do', 'dado', '.', 'automatizar', 'processo', 'e', 'fluxo', 'com', 'power', 'autom', 'e', 'python', '.', 'criar', 'e', 'otimizar', 'indicador', 'e', 'm√©trica', 'em', 'sql', 'e', 'dax', '.', 'apoiar', 'gestor', 'e', '√°rea', 'na', 'interpreta√ß√£o', 'de', 'dado', 'e', 'gera√ß√£o', 'de', 'insight', '.', 'requisito', 'power', 'bi', '(', 'modelagem', ',', 'dashboard', 'e', 'relat√≥rio', ')', 'power', 'autom', '(', 'fluxo', 'de', 'automa√ß√£o', ')', 'sql', 'e', 'sql', 'server', '(', 'consulta', ',', 'manipula√ß√£o', 'e', 'integra√ß√£o', 'de', 'dado', ')', 'dax', '(', 'cria√ß√£o', 'de', 'medida', 'e', 'c√°lculo', 'no', 'power', 'bi', ')', 'python', '(', 'tratamento', ',', 'automa√ß√£o', 'e', 'an√°lis', 'de', 'dado', ')', 'excel', 'avan√ßado', '(', 'f√≥rmula', ',', 'tabela', 'din√¢mica', ',', 'gr√°fico', ')', 'diferenciai', 'modelagem', 'e', 'estrutura√ß√£o', 'de', 'banco', 'de', 'dado', 'processo', 'de', 'etl', '(', 'extra√ß√£o', ',', 'transforma√ß√£o', 'e', 'carga', ')', 'governan√ßa', 'e', 'qualidad', 'de', 'dado', 'benef√≠cio', 'ao', 'colaborador', 'ü©∫', 'seguro', 'sa√∫d', 'üçΩÔ∏è', 'vale-alimenta√ß√£o', 'e', 'refei√ß√£o', 'na', 'modalidad', 'flex', ',', 'em', 'um', '√∫nico', 'cart√£o', '.', 'üöå', 'vale-transport', 'combo', 'bem-estar', ':', 'üèãüèΩüí™üèºüéß', 'total', 'pass', '‚Äì', 'conecta', 'o', 'colaborador', 'com', 'parceiro', 'de', 'sa√∫d', 'e', 'bem-estar', ',', 'como', 'academia', ',', 'est√∫dio', ',', 'escola', 'de', 'dan√ßa', 'etc', '.', 'üß†üíûüí≠c4life', '‚Äì', 'presta', 'suport', 'ao', 'colaborador', 'e', 'dependent', ',', 'com', 'orienta√ß√µ', 'e/ou', 'suport', 'emocion', ',', 'noss', 'pilar', ':', 'psicol√≥gico', ',', 'jur√≠dico', ',', 'financeiro', ',', 'social', 'e', 'pet', '.', 'ùöøüçé', 'clude', '-', 'oferec', 'solu√ß√µ', 'digitai', 'para', 'a', 'sa√∫d', 'do', 'corpo', 'da', 'ment', 'do', 'colaborador', '.', 'sa√∫d', 'do', 'corpo_telemedicina', '.', 'sa√∫d', 'da', 'mente_', 'telepsicologia', '.', 'nutri√ß√£o', '.', 'jornada', 'de', 'trabalho', ':', 'segunda', 'a', 'sexta-feira', '|', 'hor√°rio', 'padr√£o', ':', '8h30', '√†s', '17h30', 'modalidad', 'de', 'trabalho', ':', 'presenci', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'offic', 'local', ':', 'faria', 'lima', '-', 's√£o', 'paulo']\n",
            "Stemming pt-br:  ['sobr', 'a', 'empr', 'super', 'expect', '√©', 'o', 'que', 'no', 'motiv', '!', 'fornec', 'solu√ß', 'log√≠s', 'complet', ',', 'lider', 'o', 'set', 'com', 'inov', 'tecnol√≥g', 'configur', 'que', 'fornec', 'um', 'flux', 'cont√≠nu', 'de', 'inform', 'e', 'd√£o', '√†', 'noss', 'cresc', 'bas', 'de', 'client', 'uma', 'verd', 'visibil', 'da', 'cade', 'de', 'supr', '.', 'vem', 'trabalh', 'com', 'a', 'gent', '!', '(', 'empr', ')', 'lovers‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ', 'princip', 'ativ', 'cri', ',', 'mant', 'e', 'dar', 'suport', 'a', 'projet', 'de', 'bi', '.', 'desenvolv', 'e', 'atual', 'dashboard', 'e', 'relat√≥ri', 'em', 'pow', 'bi', 'e', 'excel', '.', 'realiz', 'an√°lis', ',', 'valid', 'e', 'trat', 'de', 'inconsist', 'no', 'dad', '.', 'elabor', 'relat√≥ri', 'gerenc', 'par', 'decis', 't√°tic', 'e', 'estrat√©g', '.', 'integr', 'e', 'mescl', 'dad', 'de', 'difer', 'plataform', ',', 'banc', 'e', 'ferrament', '.', 'garant', 'a', 'qual', ',', 'padron', 'e', 'governan√ß', 'do', 'dad', '.', 'automa', 'process', 'e', 'flux', 'com', 'pow', 'automat', 'e', 'python', '.', 'cri', 'e', 'otimiz', 'indic', 'e', 'm√©tr', 'em', 'sql', 'e', 'dax', '.', 'apoi', 'ges', 'e', '√°re', 'na', 'interpret', 'de', 'dad', 'e', 'ger', 'de', 'insight', '.', 'requisit', 'pow', 'bi', '(', 'model', ',', 'dashboard', 'e', 'relat√≥ri', ')', 'pow', 'automat', '(', 'flux', 'de', 'autom', ')', 'sql', 'e', 'sql', 'serv', '(', 'consult', ',', 'manipul', 'e', 'integr', 'de', 'dad', ')', 'dax', '(', 'cri', 'de', 'med', 'e', 'c√°lcul', 'no', 'pow', 'bi', ')', 'python', '(', 'trat', ',', 'autom', 'e', 'an√°lis', 'de', 'dad', ')', 'excel', 'avan√ß', '(', 'f√≥rmul', ',', 'tabel', 'din√¢m', ',', 'gr√°f', ')', 'difer', 'model', 'e', 'estrutur', 'de', 'banc', 'de', 'dad', 'process', 'de', 'etl', '(', 'extr', ',', 'transform', 'e', 'carg', ')', 'governan√ß', 'e', 'qual', 'de', 'dad', 'benef√≠ci', 'ao', 'colabor', 'ü©∫', 'segur', 'sa√∫d', 'üçΩÔ∏è', 'vale-aliment', 'e', 'refe', 'na', 'modal', 'flex', ',', 'em', 'um', '√∫nic', 'cart', '.', 'üöå', 'vale-transport', 'comb', 'bem-est', ':', 'üèãüèΩüí™üèºüéß', 'total', 'pas', '‚Äì', 'conect', 'o', 'colabor', 'com', 'parc', 'de', 'sa√∫d', 'e', 'bem-est', ',', 'com', 'academ', ',', 'est√∫di', ',', 'escol', 'de', 'dan√ß', 'etc', '.', 'üß†üíûüí≠c4lif', '‚Äì', 'prest', 'suport', 'ao', 'colabor', 'e', 'depend', ',', 'com', 'orient', 'e/ou', 'suport', 'emoc', ',', 'nos', 'pil', ':', 'psicol√≥g', ',', 'jur√≠d', ',', 'financ', ',', 'soc', 'e', 'pet', '.', 'ùöøüçé', 'clud', '-', 'oferec', 'solu√ß', 'digit', 'par', 'a', 'sa√∫d', 'do', 'corp', 'da', 'ment', 'do', 'colabor', '.', 'sa√∫d', 'do', 'corpo_telemedicin', '.', 'sa√∫d', 'da', 'mente_', 'telepsicolog', '.', 'nutr', '.', 'jorn', 'de', 'trabalh', ':', 'segund', 'a', 'sexta-f', '|', 'hor', 'padr', ':', '8h30', '√†s', '17h30', 'modal', 'de', 'trabalh', ':', 'presenc', ',', 'com', '1', 'dia', 'flex', '-', 'hom', 'offic', 'local', ':', 'far', 'lim', '-', 's√£o', 'paul']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatization pt-br:  ['EMPRESA', 'Superar', 'expectativa', 'motiva', '!', 'Fornecemos', 'solu√ß√£o', 'log√≠stico', 'completa', ',', 'liderar', 'setor', 'inova√ß√£o', 'tecnol√≥gico', 'configur√°vel', 'fornecer', 'fluxo', 'cont√≠nuo', 'informa√ß√£o', 'crescente', 'base', 'cliente', 'verdadeiro', 'visibilidade', 'cadeia', 'suprimento', '.', ' ', 'trabalhar', 'gente', '!', ' ', '(', 'Empresa', ')', 'Lovers', '‚ù§', 'Ô∏è', 'üö¢', '‚úà', 'Ô∏è', 'üöõ', 'üíº', 'üìà', 'üéØ', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'suporte', 'projeto', 'BI', '.', 'Desenvolver', 'atualizar', 'dashboard', 'relat√≥rio', 'Power', 'BI', 'Excel', '.', 'Realizar', 'an√°lises', ',', 'valida√ß√£o', 'tratamento', 'inconsist√™ncia', 'dado', '.', 'elaborar', 'relat√≥rio', 'gerencial', 'decis√£o', 't√°tico', 'estrat√©gico', '.', 'Integrar', 'mesclar', 'dado', 'diferente', 'plataforma', ',', 'banco', 'ferramenta', '.', 'Garantir', 'qualidade', ',', 'padroniza√ß√£o', 'governan√ßa', 'dado', '.', 'Automatizar', 'processo', 'fluxo', 'Power', 'Automate', 'Python', '.', 'Criar', 'otimizar', 'indicador', 'm√©trico', 'SQL', 'DAX', '.', 'Apoiar', 'gestor', '√°rea', 'interpreta√ß√£o', 'dado', 'gera√ß√£o', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboard', 'relat√≥rio', ')', 'Power', 'Automate', '(', 'fluxos', 'automa√ß√£o', ')', 'SQL', 'SQL', 'Server', '(', 'consulta', ',', 'manipula√ß√£o', 'integra√ß√£o', 'dado', ')', 'DAX', '(', 'cria√ß√£o', 'medida', 'c√°lculo', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automa√ß√£o', 'an√°lise', 'dado', ')', 'Excel', 'avan√ßar', '(', 'f√≥rmula', ',', 'tabela', 'din√¢mico', ',', 'gr√°fico', ')', 'DIFERENCIAIS', 'Modelagem', 'estrutura√ß√£o', 'banco', 'dado', 'Processos', 'ETL', '(', 'extra√ß√£o', ',', 'transforma√ß√£o', 'carga', ')', 'Governan√ßa', 'qualidade', 'dado', 'BENEF√çCIOS', 'COLABORADORES', 'ü©∫', 'seguro', 'Sa√∫de', 'üçΩ', 'Ô∏è', 'Vale-Alimenta√ß√£o', 'Refei√ß√£o', 'modalidade', 'flex', ',', '√∫nico', 'cart√£o', '.', 'üöå', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', 'üèã', 'üèΩ', 'üí™', 'üèº', 'üéß', 'Total', 'Pass', '‚Äì', 'conectar', 'colaborador', 'parceiro', 'sa√∫de', 'bem-estar', ',', 'academia', ',', 'est√∫dio', ',', 'escola', 'dan√ßa', 'etc.', 'üß†', 'üíû', 'üí≠', 'C4Life', '‚Äì', 'presta', 'suporte', 'colaborador', 'dependente', ',', 'orienta√ß√£o', 'e/ou', 'suporte', 'emocional', ',', 'nossr', 'pilar', ':', 'Psicol√≥gico', ',', 'Jur√≠dico', ',', 'Financeiro', ',', 'Social', 'Pets', '.', 'ùöø', 'üçé', 'clude', '-', 'oferecer', 'solu√ß√£o', 'digital', 'sa√∫de', 'corpo', 'mente', 'colaborador', '.', 'sa√∫de', 'Corpo_Telemedicina', '.', 'Sa√∫de', 'Mente', '_', 'Telepsicologia', '.', 'Nutri√ß√£o', '.', 'Jornada', 'trabalho', ':', 'sexta-feira', '|', 'Hor√°rio', 'padr√£o', ':', '8h30', '17h30', 'Modalidade', 'trabalho', ':', 'presencial', ',', '1', 'dia', 'flex', '-', 'home', 'office', ' ', ':', 'Faria', 'Lima', '-', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "# Testando a Stematiza√ß√£o\n",
        "porter = nltk.PorterStemmer()\n",
        "print(\"Stemming: \", [porter.stem(i) for i in text])\n",
        "\n",
        "\n",
        "# Agora com um algoritmo para portugu√™s pt-br\n",
        "from nltk.stem import RSLPStemmer\n",
        "nltk.download('rslp')\n",
        "\n",
        "rlsp = RSLPStemmer()\n",
        "print(\"Stemming pt-br: \", [rlsp.stem(i) for i in text])\n",
        "\n",
        "# Lematiza√ß√£o para pt-br agora\n",
        "import spacy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "doc = nlp(raw)\n",
        "print(\"Lemmatization pt-br: \", [i.lemma_ for i in doc if not i.is_stop]) # essa condicional remove as stop words, o que j√° ajuda a diminuir o tamanho das descri√ß√µes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHjmxOAc1VmN"
      },
      "source": [
        "### Conclus√£o (M√≥dulo de Pr√©-Processamento Finalizado)\n",
        "\n",
        "O melhor algoritmo para n√≥s ser√° o lematizador do spacy, pois ele √© quem funciona para pt-br e manteve a estrutura das palavras melhor.\n",
        "\n",
        "Mas na tokeniza√ß√£o vemos que h√° uma lista de termos que s√£o mais de uma palavra, exemplo: power bi, power automate, SQL Server, Banco de dados, S√£o Paulo, etc. Estes termos s√£o separados como se n√£o fizessem parte de uma coisa s√≥.\n",
        "\n",
        "Para resolvermos isso, precisaremos de um pr√©-tokenizador: ele ir√° exrair os termos de uma lista e compar√°-los com o texto que queremos processar, e, ao encontr√°-los, trocar o whitespace por um urderscore.\n",
        "\n",
        "</br>\n",
        "\n",
        "Com este pipeline de pr√©-processamento validado, a l√≥gica das fun√ß√µes replace_multiword_expressions, preprocess_with_nltk e lemmatize_tokens ser√° extra√≠da deste notebook e implementada como um m√≥dulo Python (.py) dentro da arquitetura do backend (src/backend/processing/nlp_utils.py). Isso garantir√° que o mesmo tratamento de texto explorado aqui seja aplicado de forma consistente aos dados que entram no banco de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiWoN6W0AWOE"
      },
      "outputs": [],
      "source": [
        "# !pip install -q spacy\n",
        "# !python -m spacy download pt_core_news_sm\n",
        "\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlPS-yN_2Bm5"
      },
      "outputs": [],
      "source": [
        "# queremos diferenciar essas listas para usar a technical_terms no autocomplete do dataentry de skills do frontend.\n",
        "technical_terms = [\"Power BI\", \"Power Automate\", \"Banco de dados\", \"SQL Server\"]\n",
        "locale_terms = [\"S√£o Paulo\"]\n",
        "\n",
        "\n",
        "# Registra cada termo como uma \"special case\" para tokeniza√ß√£o, ent√£o os termos com palavras compostas ser√£o tradados como unidade, e n√£o divididos. Ex: power bi -> 'power', 'bi'\n",
        "for terms in [technical_terms, locale_terms]:\n",
        "  for term in terms:\n",
        "      nlp.tokenizer.add_special_case(term.lower(), [{ORTH: term.lower()}])\n",
        "\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    lemmas = [\n",
        "        token.lemma_.lower()\n",
        "        for token in doc\n",
        "        if not token.is_stop and not token.is_punct\n",
        "    ]\n",
        "\n",
        "    # Reverte \"_\" para espa√ßos, se quiser manter legibilidade\n",
        "    lemmas = [lemma.replace(\"_\", \" \") for lemma in lemmas]\n",
        "\n",
        "    return \" \".join(lemmas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBaG_B9C-AnN",
        "outputId": "ac3575f9-5587-416a-f378-4bb7e97163bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10789847373962402\n"
          ]
        }
      ],
      "source": [
        "jobs = [\n",
        "    \"SOBRE A EMPRESA Superar expectativas √© o que nos motiva! Fornecemos solu√ß√µes log√≠sticas completas, liderando o setor com inova√ß√µes tecnol√≥gicas configur√°veis que fornecem um fluxo cont√≠nuo de informa√ß√µes e d√£o √† nossa crescente base de clientes uma verdadeira visibilidade da cadeia de suprimentos.  Vem trabalhar com a gente!  (Empresa) Lovers‚ù§Ô∏èüö¢‚úàÔ∏èüöõüíºüìàüéØ PRINCIPAIS ATIVIDADES Criar, manter e dar suporte a projetos de BI. Desenvolver e atualizar dashboards e relat√≥rios em Power BI e Excel. Realizar an√°lises, valida√ß√µes e tratamento de inconsist√™ncias nos dados. Elaborar relat√≥rios gerenciais para decis√µes t√°ticas e estrat√©gicas. Integrar e mesclar dados de diferentes plataformas, bancos e ferramentas. Garantir a qualidade, padroniza√ß√£o e governan√ßa dos dados. Automatizar processos e fluxos com Power Automate e Python. Criar e otimizar indicadores e m√©tricas em SQL e DAX. Apoiar gestores e √°reas na interpreta√ß√£o de dados e gera√ß√£o de insights. REQUISITOS Power BI (modelagem, dashboards e relat√≥rios) Power Automate (fluxos de automa√ß√£o) SQL e SQL Server (consultas, manipula√ß√£o e integra√ß√£o de dados) DAX (cria√ß√£o de medidas e c√°lculos no Power BI) Python (tratamento, automa√ß√£o e an√°lise de dados) Excel avan√ßado (f√≥rmulas, tabelas din√¢micas, gr√°ficos) DIFERENCIAIS Modelagem e estrutura√ß√£o de banco de dados Processos de ETL (extra√ß√£o, transforma√ß√£o e carga) Governan√ßa e qualidade de dados BENEF√çCIOS AOS COLABORADORES ü©∫ Seguro Sa√∫de üçΩÔ∏è Vale-Alimenta√ß√£o e Refei√ß√£o na modalidade flex, em um √∫nico cart√£o. üöå Vale-Transporte COMBO BEM-ESTAR: üèãüèΩüí™üèºüéß Total Pass ‚Äì conecta o colaborador com parceiros de sa√∫de e bem-estar, como academias, est√∫dios, escolas de dan√ßa etc. üß†üíûüí≠C4Life ‚Äì presta suporte aos colaboradores e dependentes, com orienta√ß√µes e/ou suporte emocional, noss pilares: Psicol√≥gico, Jur√≠dico, Financeiro, Social e Pets. ùöøüçé Clude - oferece solu√ß√µes digitais para a sa√∫de do corpo da mente dos colaboradores. Sa√∫de do Corpo_Telemedicina. Sa√∫de da Mente_ Telepsicologia. Nutri√ß√£o. Jornada de trabalho: Segunda a sexta-feira | Hor√°rio padr√£o: 8h30 √†s 17h30 Modalidade de trabalho: presencial, com 1 dia flex - home office  Local: Faria Lima - S√£o Paulo\",\n",
        "\"\"\n",
        "\n",
        "]\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "for i in jobs:\n",
        "  preprocess_text_spacy(i)\n",
        "\n",
        "print(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOS4WmyER10"
      },
      "source": [
        "## Cap√≠tulo 6\n",
        "\n",
        "Baseado neste cap√≠tulo, ser√° feito o processamento dos textos (estes j√° pr√©-processados) com o algoritmo TF-IDF do scikit-learn\n",
        "\n",
        "Detalhes importantes\n",
        "-\n",
        "\n",
        "- **Limita√ß√£o do TF-IDF:** Considerando que usaremos o TF-IDF, o IDF far√° com que os termos mais frequentes \"percam for√ßa\", ent√£o faremos uma m√©dia ponderada com o TF, para que palavras muito frequentes, tais como Excel, Power BI, e etc ainda se mantenham relevantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a52M5BrXSdHW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\ATIVA\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ativa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.1.0)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
            "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
            "   -------------------------------------- - 8.7/8.9 MB 48.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.9/8.9 MB 30.7 MB/s eta 0:00:00\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl (38.7 MB)\n",
            "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 10.7/38.7 MB 51.7 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 21.0/38.7 MB 51.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 32.2/38.7 MB 51.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  38.5/38.7 MB 51.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.7/38.7 MB 39.7 MB/s eta 0:00:00\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID7fIdTLEUcb"
      },
      "outputs": [],
      "source": [
        "vagas = [\n",
        "    \"analista de dados python sql power bi dashboards relat√≥rios\",\n",
        "    \"desenvolvedor java spring api microsservi√ßos\",\n",
        "    \"cientista de dados python machine learning deep learning\",\n",
        "    \"engenheiro de dados spark hadoop python airflow\"\n",
        "]\n",
        "\n",
        "# treinando os modelos\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=2000) # podemos adicionar um par√¢metro 'max_features' para limitar a quantidade de elementos por vetor\n",
        "count = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(vagas) # treinando o tf-idf\n",
        "count_matrix = count.fit_transform(vagas) # treinando o tf apenas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIKt6_vQTrFs",
        "outputId": "2dbd8baa-48f7-44f6-9b4c-f5569f336033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.34488069 0.         0.         0.         0.         0.\n",
            "  0.34488069 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.34488069 0.34488069 0.\n",
            "  0.22013288 0.34488069 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.34488069 0.34488069 0.34488069]]\n"
          ]
        }
      ],
      "source": [
        "# agora devemos fazer o mesmo processo de treinamento do algoritmo, mas com os inputs do usu√°rio. Para o nosso exemplo, vamos supor que seja esta lista:\n",
        "list_user_skills = ['python', 'airflow', 'sql', 'power bi', 'teste', 'dwedw', 'dwdwdw']\n",
        "list_user_skills = ' '.join(list_user_skills)\n",
        "\n",
        "\n",
        "tfidf_user = tfidf.transform([list_user_skills]) # o tfidf do usu√°rio PRECISA estar no mesmo espa√ßo vetorial do algoritmo das vagas.\n",
        "tfidf_user = tfidf.transform([list_user_skills]) \n",
        "\n",
        "print(tfidf_user.toarray())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
