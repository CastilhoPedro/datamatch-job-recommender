{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN2orzSqF-iF"
      },
      "source": [
        "# Natural Language Processing with Python\n",
        "\n",
        "<br>\n",
        "\n",
        "Neste notebook será construído o algoritmo para o módulo de NLP do DataMatch, aquele usará como base o livro Natural Language Processing with Python. (Capítulos 3, 5, 6)\n",
        "\n",
        "- No capítulo 3 aprenderemos sobre o processamento do texto;\n",
        "\n",
        "- No 5 aprenderemos o Part-of-Speech (POS) tagging, para saber o que ele identifica como substantivo, adjetivo, e etc. <- útil para, por exemplo, filtrarmos apenas os substantivos: Python, SQL, etc.\n",
        "\n",
        "- No cap 6...\n",
        "\n",
        "Link do livro: https://tjzhifei.github.io/resources/NLTK.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywp-N_EAGjdx"
      },
      "source": [
        "## Capítulo 3\n",
        "\n",
        "Anotações Importantes:\n",
        "-\n",
        "- **Tokenização:** É o processo de quebrar um texto em vários tokens, ou seja, várias palavras separadas. Ex: \"Eu gosto de NLP.\" -> ['Eu', 'gosto', 'de', 'NLP', '.']\n",
        "\n",
        "\n",
        "- **Normalização:** primeira coisa será transformar tudo em lowercase, para isso, usaremos o lower() do Python, além disso teremos:\n",
        "\n",
        "  - Stematização: o Stem de uma palavra é a sua raíz léxica. Ex: andando -> anda. Então stematizar é cortar o sulfixo da palavra para que, por exemplo, a palavra \"Requisito\" e \"Requisitos\" se tornem a mesma coisa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMlmzU3MF2-q",
        "outputId": "f056b305-18ea-442c-f8b9-842776ea324a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "import nltk, re\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "!pip install -q spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx58gA3nG-9S",
        "outputId": "7d176a3b-2a41-44b2-c7c6-3ea844f7640a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', 'é', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'soluções', 'logísticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inovações', 'tecnológicas', 'configuráveis', 'que', 'fornecem', 'um', 'fluxo', 'contínuo', 'de', 'informações', 'e', 'dão', 'à', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers❤️🚢✈️🚛💼📈🎯', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relatórios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'análises', ',', 'validações', 'e', 'tratamento', 'de', 'inconsistências', 'nos', 'dados', '.', 'Elaborar', 'relatórios', 'gerenciais', 'para', 'decisões', 'táticas', 'e', 'estratégicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padronização', 'e', 'governança', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'métricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', 'áreas', 'na', 'interpretação', 'de', 'dados', 'e', 'geração', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relatórios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automação', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipulação', 'e', 'integração', 'de', 'dados', ')', 'DAX', '(', 'criação', 'de', 'medidas', 'e', 'cálculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automação', 'e', 'análise', 'de', 'dados', ')', 'Excel', 'avançado', '(', 'fórmulas', ',', 'tabelas', 'dinâmicas', ',', 'gráficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estruturação', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extração', ',', 'transformação', 'e', 'carga', ')', 'Governança', 'e', 'qualidade', 'de', 'dados', 'BENEFÍCIOS', 'AOS', 'COLABORADORES', '🩺', 'Seguro', 'Saúde', '🍽️', 'Vale-Alimentação', 'e', 'Refeição', 'na', 'modalidade', 'flex', ',', 'em', 'um', 'único', 'cartão', '.', '🚌', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', '🏋🏽💪🏼🎧', 'Total', 'Pass', '–', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'saúde', 'e', 'bem-estar', ',', 'como', 'academias', ',', 'estúdios', ',', 'escolas', 'de', 'dança', 'etc', '.', '🧠💞💭C4Life', '–', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orientações', 'e/ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicológico', ',', 'Jurídico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', '𝚿🍎', 'Clude', '-', 'oferece', 'soluções', 'digitais', 'para', 'a', 'saúde', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Saúde', 'do', 'Corpo_Telemedicina', '.', 'Saúde', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutrição', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta-feira', '|', 'Horário', 'padrão', ':', '8h30', 'às', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'São', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "raw = \"SOBRE A EMPRESA Superar expectativas é o que nos motiva! Fornecemos soluções logísticas completas, liderando o setor com inovações tecnológicas configuráveis que fornecem um fluxo contínuo de informações e dão à nossa crescente base de clientes uma verdadeira visibilidade da cadeia de suprimentos.  Vem trabalhar com a gente!  (Empresa) Lovers❤️🚢✈️🚛💼📈🎯 PRINCIPAIS ATIVIDADES Criar, manter e dar suporte a projetos de BI. Desenvolver e atualizar dashboards e relatórios em Power BI e Excel. Realizar análises, validações e tratamento de inconsistências nos dados. Elaborar relatórios gerenciais para decisões táticas e estratégicas. Integrar e mesclar dados de diferentes plataformas, bancos e ferramentas. Garantir a qualidade, padronização e governança dos dados. Automatizar processos e fluxos com Power Automate e Python. Criar e otimizar indicadores e métricas em SQL e DAX. Apoiar gestores e áreas na interpretação de dados e geração de insights. REQUISITOS Power BI (modelagem, dashboards e relatórios) Power Automate (fluxos de automação) SQL e SQL Server (consultas, manipulação e integração de dados) DAX (criação de medidas e cálculos no Power BI) Python (tratamento, automação e análise de dados) Excel avançado (fórmulas, tabelas dinâmicas, gráficos) DIFERENCIAIS Modelagem e estruturação de banco de dados Processos de ETL (extração, transformação e carga) Governança e qualidade de dados BENEFÍCIOS AOS COLABORADORES 🩺 Seguro Saúde 🍽️ Vale-Alimentação e Refeição na modalidade flex, em um único cartão. 🚌 Vale-Transporte COMBO BEM-ESTAR: 🏋🏽💪🏼🎧 Total Pass – conecta o colaborador com parceiros de saúde e bem-estar, como academias, estúdios, escolas de dança etc. 🧠💞💭C4Life – presta suporte aos colaboradores e dependentes, com orientações e/ou suporte emocional, noss pilares: Psicológico, Jurídico, Financeiro, Social e Pets. 𝚿🍎 Clude - oferece soluções digitais para a saúde do corpo da mente dos colaboradores. Saúde do Corpo_Telemedicina. Saúde da Mente_ Telepsicologia. Nutrição. Jornada de trabalho: Segunda a sexta-feira | Horário padrão: 8h30 às 17h30 Modalidade de trabalho: presencial, com 1 dia flex - home office  Local: Faria Lima - São Paulo\"\n",
        "\n",
        "tokens = nltk.word_tokenize(raw) # tokenizador padrão.\n",
        "text = nltk.Text(tokens) # conceito mais avançado, útil para análises exploratórias.\n",
        "\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SamP4fCGzgYH",
        "outputId": "1a8be251-8ca5-4859-ebe5-6e4d2390f31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', 'é', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'soluções', 'logísticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inovações', 'tecnológicas', 'configuráveis', 'que', 'fornecem', 'um', 'fluxo', 'contínuo', 'de', 'informações', 'e', 'dão', 'à', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers', '❤', '️', '🚢', '✈', '️', '🚛', '💼', '📈', '🎯', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relatórios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'análises', ',', 'validações', 'e', 'tratamento', 'de', 'inconsistências', 'nos', 'dados', '.', 'Elaborar', 'relatórios', 'gerenciais', 'para', 'decisões', 'táticas', 'e', 'estratégicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padronização', 'e', 'governança', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'métricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', 'áreas', 'na', 'interpretação', 'de', 'dados', 'e', 'geração', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relatórios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automação', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipulação', 'e', 'integração', 'de', 'dados', ')', 'DAX', '(', 'criação', 'de', 'medidas', 'e', 'cálculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automação', 'e', 'análise', 'de', 'dados', ')', 'Excel', 'avançado', '(', 'fórmulas', ',', 'tabelas', 'dinâmicas', ',', 'gráficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estruturação', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extração', ',', 'transformação', 'e', 'carga', ')', 'Governança', 'e', 'qualidade', 'de', 'dados', 'BENEFÍCIOS', 'AOS', 'COLABORADORES', '🩺', 'Seguro', 'Saúde', '🍽', '️', 'Vale-Alimentação', 'e', 'Refeição', 'na', 'modalidade', 'flex', ',', 'em', 'um', 'único', 'cartão', '.', '🚌', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', '🏋', '🏽', '💪', '🏼', '🎧', 'Total', 'Pass', '–', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'saúde', 'e', 'bem-estar', ',', 'como', 'academias', ',', 'estúdios', ',', 'escolas', 'de', 'dança', 'etc', '.', '🧠', '💞', '💭C4Life', '–', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orientações', 'e', '/ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicológico', ',', 'Jurídico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', '𝚿', '🍎', 'Clude', '-', 'oferece', 'soluções', 'digitais', 'para', 'a', 'saúde', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Saúde', 'do', 'Corpo_Telemedicina', '.', 'Saúde', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutrição', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta-feira', '|', 'Horário', 'padrão', ':', '8h30', 'às', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'São', 'Paulo']\n",
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', 'é', 'o', 'que', 'nos', 'motiva', 'Fornecemos', 'soluções', 'logísticas', 'completas', 'liderando', 'o', 'setor', 'com', 'inovações', 'tecnológicas', 'configuráveis', 'que', 'fornecem', 'um', 'fluxo', 'contínuo', 'de', 'informações', 'e', 'dão', 'à', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', 'Vem', 'trabalhar', 'com', 'a', 'gente', 'Empresa', 'Lovers', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relatórios', 'em', 'Power', 'BI', 'e', 'Excel', 'Realizar', 'análises', 'validações', 'e', 'tratamento', 'de', 'inconsistências', 'nos', 'dados', 'Elaborar', 'relatórios', 'gerenciais', 'para', 'decisões', 'táticas', 'e', 'estratégicas', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', 'bancos', 'e', 'ferramentas', 'Garantir', 'a', 'qualidade', 'padronização', 'e', 'governança', 'dos', 'dados', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'métricas', 'em', 'SQL', 'e', 'DAX', 'Apoiar', 'gestores', 'e', 'áreas', 'na', 'interpretação', 'de', 'dados', 'e', 'geração', 'de', 'insights', 'REQUISITOS', 'Power', 'BI', 'modelagem', 'dashboards', 'e', 'relatórios', 'Power', 'Automate', 'fluxos', 'de', 'automação', 'SQL', 'e', 'SQL', 'Server', 'consultas', 'manipulação', 'e', 'integração', 'de', 'dados', 'DAX', 'criação', 'de', 'medidas', 'e', 'cálculos', 'no', 'Power', 'BI', 'Python', 'tratamento', 'automação', 'e', 'análise', 'de', 'dados', 'Excel', 'avançado', 'fórmulas', 'tabelas', 'dinâmicas', 'gráficos', 'DIFERENCIAIS', 'Modelagem', 'e', 'estruturação', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', 'extração', 'transformação', 'e', 'carga', 'Governança', 'e', 'qualidade', 'de', 'dados', 'BENEFÍCIOS', 'AOS', 'COLABORADORES', 'Seguro', 'Saúde', 'Vale', 'Alimentação', 'e', 'Refeição', 'na', 'modalidade', 'flex', 'em', 'um', 'único', 'cartão', 'Vale', 'Transporte', 'COMBO', 'BEM', 'ESTAR', 'Total', 'Pass', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'saúde', 'e', 'bem', 'estar', 'como', 'academias', 'estúdios', 'escolas', 'de', 'dança', 'etc', 'C4Life', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', 'com', 'orientações', 'e', 'ou', 'suporte', 'emocional', 'noss', 'pilares', 'Psicológico', 'Jurídico', 'Financeiro', 'Social', 'e', 'Pets', '𝚿', 'Clude', 'oferece', 'soluções', 'digitais', 'para', 'a', 'saúde', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', 'Saúde', 'do', 'Corpo_Telemedicina', 'Saúde', 'da', 'Mente_', 'Telepsicologia', 'Nutrição', 'Jornada', 'de', 'trabalho', 'Segunda', 'a', 'sexta', 'feira', 'Horário', 'padrão', '8h30', 'às', '17h30', 'Modalidade', 'de', 'trabalho', 'presencial', 'com', '1', 'dia', 'flex', 'home', 'office', 'Local', 'Faria', 'Lima', 'São', 'Paulo']\n",
            "['SOBRE', 'A', 'EMPRESA', 'Superar', 'expectativas', 'é', 'o', 'que', 'nos', 'motiva', '!', 'Fornecemos', 'soluções', 'logísticas', 'completas', ',', 'liderando', 'o', 'setor', 'com', 'inovações', 'tecnológicas', 'configuráveis', 'que', 'fornecem', 'um', 'fluxo', 'contínuo', 'de', 'informações', 'e', 'dão', 'à', 'nossa', 'crescente', 'base', 'de', 'clientes', 'uma', 'verdadeira', 'visibilidade', 'da', 'cadeia', 'de', 'suprimentos', '.', 'Vem', 'trabalhar', 'com', 'a', 'gente', '!', '(', 'Empresa', ')', 'Lovers', '❤️🚢✈️🚛💼📈🎯', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'e', 'dar', 'suporte', 'a', 'projetos', 'de', 'BI', '.', 'Desenvolver', 'e', 'atualizar', 'dashboards', 'e', 'relatórios', 'em', 'Power', 'BI', 'e', 'Excel', '.', 'Realizar', 'análises', ',', 'validações', 'e', 'tratamento', 'de', 'inconsistências', 'nos', 'dados', '.', 'Elaborar', 'relatórios', 'gerenciais', 'para', 'decisões', 'táticas', 'e', 'estratégicas', '.', 'Integrar', 'e', 'mesclar', 'dados', 'de', 'diferentes', 'plataformas', ',', 'bancos', 'e', 'ferramentas', '.', 'Garantir', 'a', 'qualidade', ',', 'padronização', 'e', 'governança', 'dos', 'dados', '.', 'Automatizar', 'processos', 'e', 'fluxos', 'com', 'Power', 'Automate', 'e', 'Python', '.', 'Criar', 'e', 'otimizar', 'indicadores', 'e', 'métricas', 'em', 'SQL', 'e', 'DAX', '.', 'Apoiar', 'gestores', 'e', 'áreas', 'na', 'interpretação', 'de', 'dados', 'e', 'geração', 'de', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboards', 'e', 'relatórios', ')', 'Power', 'Automate', '(', 'fluxos', 'de', 'automação', ')', 'SQL', 'e', 'SQL', 'Server', '(', 'consultas', ',', 'manipulação', 'e', 'integração', 'de', 'dados', ')', 'DAX', '(', 'criação', 'de', 'medidas', 'e', 'cálculos', 'no', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automação', 'e', 'análise', 'de', 'dados', ')', 'Excel', 'avançado', '(', 'fórmulas', ',', 'tabelas', 'dinâmicas', ',', 'gráficos', ')', 'DIFERENCIAIS', 'Modelagem', 'e', 'estruturação', 'de', 'banco', 'de', 'dados', 'Processos', 'de', 'ETL', '(', 'extração', ',', 'transformação', 'e', 'carga', ')', 'Governança', 'e', 'qualidade', 'de', 'dados', 'BENEFÍCIOS', 'AOS', 'COLABORADORES', '🩺', 'Seguro', 'Saúde', '🍽️', 'Vale', '-', 'Alimentação', 'e', 'Refeição', 'na', 'modalidade', 'flex', ',', 'em', 'um', 'único', 'cartão', '.', '🚌', 'Vale', '-', 'Transporte', 'COMBO', 'BEM', '-', 'ESTAR', ':', '🏋🏽💪🏼🎧', 'Total', 'Pass', '–', 'conecta', 'o', 'colaborador', 'com', 'parceiros', 'de', 'saúde', 'e', 'bem', '-', 'estar', ',', 'como', 'academias', ',', 'estúdios', ',', 'escolas', 'de', 'dança', 'etc', '.', '🧠💞💭', 'C4Life', '–', 'presta', 'suporte', 'aos', 'colaboradores', 'e', 'dependentes', ',', 'com', 'orientações', 'e', '/', 'ou', 'suporte', 'emocional', ',', 'noss', 'pilares', ':', 'Psicológico', ',', 'Jurídico', ',', 'Financeiro', ',', 'Social', 'e', 'Pets', '.', '𝚿', '🍎', 'Clude', '-', 'oferece', 'soluções', 'digitais', 'para', 'a', 'saúde', 'do', 'corpo', 'da', 'mente', 'dos', 'colaboradores', '.', 'Saúde', 'do', 'Corpo_Telemedicina', '.', 'Saúde', 'da', 'Mente_', 'Telepsicologia', '.', 'Nutrição', '.', 'Jornada', 'de', 'trabalho', ':', 'Segunda', 'a', 'sexta', '-', 'feira', '|', 'Horário', 'padrão', ':', '8h30', 'às', '17h30', 'Modalidade', 'de', 'trabalho', ':', 'presencial', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'office', 'Local', ':', 'Faria', 'Lima', '-', 'São', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "# Outras formas de tokenizar\n",
        "teste = re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw)\n",
        "print(teste)\n",
        "teste = re.split(r'\\W+', raw)\n",
        "print(teste)\n",
        "teste = nltk.regexp_tokenize(raw, pattern=r\"\\w+(?:'\\w+)?|[^\\w\\s]+\")\n",
        "print(teste)\n",
        "\n",
        "# Outro exemplo abaixo:\n",
        "\n",
        "# text = 'That U.S.A. poster-print costs $12.40...'\n",
        "# pattern = r'(?x)'\n",
        "# ... ([A-Z]\\.)+ # abbreviations, e.g. U.S.A.\n",
        "# ... | \\w+(-\\w+)* # words with optional internal hyphens\n",
        "# ... | \\$?\\d+(\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
        "# ... | \\.\\.\\. # ellipsis\n",
        "# ... | [][.,;\"'?():-_`] # these are separate tokens\n",
        "# nltk.regexp_tokenize(text, pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRZR8mvEOEiA",
        "outputId": "f4bf9566-0f98-400d-e8ea-d4574fdcbd8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming:  ['sobr', 'a', 'empresa', 'superar', 'expectativa', 'é', 'o', 'que', 'no', 'motiva', '!', 'fornecemo', 'soluçõ', 'logística', 'completa', ',', 'liderando', 'o', 'setor', 'com', 'inovaçõ', 'tecnológica', 'configurávei', 'que', 'fornecem', 'um', 'fluxo', 'contínuo', 'de', 'informaçõ', 'e', 'dão', 'à', 'nossa', 'crescent', 'base', 'de', 'client', 'uma', 'verdadeira', 'visibilidad', 'da', 'cadeia', 'de', 'suprimento', '.', 'vem', 'trabalhar', 'com', 'a', 'gent', '!', '(', 'empresa', ')', 'lovers❤️🚢✈️🚛💼📈🎯', 'principai', 'atividad', 'criar', ',', 'manter', 'e', 'dar', 'suport', 'a', 'projeto', 'de', 'bi', '.', 'desenvolv', 'e', 'atualizar', 'dashboard', 'e', 'relatório', 'em', 'power', 'bi', 'e', 'excel', '.', 'realizar', 'anális', ',', 'validaçõ', 'e', 'tratamento', 'de', 'inconsistência', 'no', 'dado', '.', 'elaborar', 'relatório', 'gerenciai', 'para', 'decisõ', 'tática', 'e', 'estratégica', '.', 'integrar', 'e', 'mesclar', 'dado', 'de', 'diferent', 'plataforma', ',', 'banco', 'e', 'ferramenta', '.', 'garantir', 'a', 'qualidad', ',', 'padronização', 'e', 'governança', 'do', 'dado', '.', 'automatizar', 'processo', 'e', 'fluxo', 'com', 'power', 'autom', 'e', 'python', '.', 'criar', 'e', 'otimizar', 'indicador', 'e', 'métrica', 'em', 'sql', 'e', 'dax', '.', 'apoiar', 'gestor', 'e', 'área', 'na', 'interpretação', 'de', 'dado', 'e', 'geração', 'de', 'insight', '.', 'requisito', 'power', 'bi', '(', 'modelagem', ',', 'dashboard', 'e', 'relatório', ')', 'power', 'autom', '(', 'fluxo', 'de', 'automação', ')', 'sql', 'e', 'sql', 'server', '(', 'consulta', ',', 'manipulação', 'e', 'integração', 'de', 'dado', ')', 'dax', '(', 'criação', 'de', 'medida', 'e', 'cálculo', 'no', 'power', 'bi', ')', 'python', '(', 'tratamento', ',', 'automação', 'e', 'anális', 'de', 'dado', ')', 'excel', 'avançado', '(', 'fórmula', ',', 'tabela', 'dinâmica', ',', 'gráfico', ')', 'diferenciai', 'modelagem', 'e', 'estruturação', 'de', 'banco', 'de', 'dado', 'processo', 'de', 'etl', '(', 'extração', ',', 'transformação', 'e', 'carga', ')', 'governança', 'e', 'qualidad', 'de', 'dado', 'benefício', 'ao', 'colaborador', '🩺', 'seguro', 'saúd', '🍽️', 'vale-alimentação', 'e', 'refeição', 'na', 'modalidad', 'flex', ',', 'em', 'um', 'único', 'cartão', '.', '🚌', 'vale-transport', 'combo', 'bem-estar', ':', '🏋🏽💪🏼🎧', 'total', 'pass', '–', 'conecta', 'o', 'colaborador', 'com', 'parceiro', 'de', 'saúd', 'e', 'bem-estar', ',', 'como', 'academia', ',', 'estúdio', ',', 'escola', 'de', 'dança', 'etc', '.', '🧠💞💭c4life', '–', 'presta', 'suport', 'ao', 'colaborador', 'e', 'dependent', ',', 'com', 'orientaçõ', 'e/ou', 'suport', 'emocion', ',', 'noss', 'pilar', ':', 'psicológico', ',', 'jurídico', ',', 'financeiro', ',', 'social', 'e', 'pet', '.', '𝚿🍎', 'clude', '-', 'oferec', 'soluçõ', 'digitai', 'para', 'a', 'saúd', 'do', 'corpo', 'da', 'ment', 'do', 'colaborador', '.', 'saúd', 'do', 'corpo_telemedicina', '.', 'saúd', 'da', 'mente_', 'telepsicologia', '.', 'nutrição', '.', 'jornada', 'de', 'trabalho', ':', 'segunda', 'a', 'sexta-feira', '|', 'horário', 'padrão', ':', '8h30', 'às', '17h30', 'modalidad', 'de', 'trabalho', ':', 'presenci', ',', 'com', '1', 'dia', 'flex', '-', 'home', 'offic', 'local', ':', 'faria', 'lima', '-', 'são', 'paulo']\n",
            "Stemming pt-br:  ['sobr', 'a', 'empr', 'super', 'expect', 'é', 'o', 'que', 'no', 'motiv', '!', 'fornec', 'soluç', 'logís', 'complet', ',', 'lider', 'o', 'set', 'com', 'inov', 'tecnológ', 'configur', 'que', 'fornec', 'um', 'flux', 'contínu', 'de', 'inform', 'e', 'dão', 'à', 'noss', 'cresc', 'bas', 'de', 'client', 'uma', 'verd', 'visibil', 'da', 'cade', 'de', 'supr', '.', 'vem', 'trabalh', 'com', 'a', 'gent', '!', '(', 'empr', ')', 'lovers❤️🚢✈️🚛💼📈🎯', 'princip', 'ativ', 'cri', ',', 'mant', 'e', 'dar', 'suport', 'a', 'projet', 'de', 'bi', '.', 'desenvolv', 'e', 'atual', 'dashboard', 'e', 'relatóri', 'em', 'pow', 'bi', 'e', 'excel', '.', 'realiz', 'anális', ',', 'valid', 'e', 'trat', 'de', 'inconsist', 'no', 'dad', '.', 'elabor', 'relatóri', 'gerenc', 'par', 'decis', 'tátic', 'e', 'estratég', '.', 'integr', 'e', 'mescl', 'dad', 'de', 'difer', 'plataform', ',', 'banc', 'e', 'ferrament', '.', 'garant', 'a', 'qual', ',', 'padron', 'e', 'governanç', 'do', 'dad', '.', 'automa', 'process', 'e', 'flux', 'com', 'pow', 'automat', 'e', 'python', '.', 'cri', 'e', 'otimiz', 'indic', 'e', 'métr', 'em', 'sql', 'e', 'dax', '.', 'apoi', 'ges', 'e', 'áre', 'na', 'interpret', 'de', 'dad', 'e', 'ger', 'de', 'insight', '.', 'requisit', 'pow', 'bi', '(', 'model', ',', 'dashboard', 'e', 'relatóri', ')', 'pow', 'automat', '(', 'flux', 'de', 'autom', ')', 'sql', 'e', 'sql', 'serv', '(', 'consult', ',', 'manipul', 'e', 'integr', 'de', 'dad', ')', 'dax', '(', 'cri', 'de', 'med', 'e', 'cálcul', 'no', 'pow', 'bi', ')', 'python', '(', 'trat', ',', 'autom', 'e', 'anális', 'de', 'dad', ')', 'excel', 'avanç', '(', 'fórmul', ',', 'tabel', 'dinâm', ',', 'gráf', ')', 'difer', 'model', 'e', 'estrutur', 'de', 'banc', 'de', 'dad', 'process', 'de', 'etl', '(', 'extr', ',', 'transform', 'e', 'carg', ')', 'governanç', 'e', 'qual', 'de', 'dad', 'benefíci', 'ao', 'colabor', '🩺', 'segur', 'saúd', '🍽️', 'vale-aliment', 'e', 'refe', 'na', 'modal', 'flex', ',', 'em', 'um', 'únic', 'cart', '.', '🚌', 'vale-transport', 'comb', 'bem-est', ':', '🏋🏽💪🏼🎧', 'total', 'pas', '–', 'conect', 'o', 'colabor', 'com', 'parc', 'de', 'saúd', 'e', 'bem-est', ',', 'com', 'academ', ',', 'estúdi', ',', 'escol', 'de', 'danç', 'etc', '.', '🧠💞💭c4lif', '–', 'prest', 'suport', 'ao', 'colabor', 'e', 'depend', ',', 'com', 'orient', 'e/ou', 'suport', 'emoc', ',', 'nos', 'pil', ':', 'psicológ', ',', 'juríd', ',', 'financ', ',', 'soc', 'e', 'pet', '.', '𝚿🍎', 'clud', '-', 'oferec', 'soluç', 'digit', 'par', 'a', 'saúd', 'do', 'corp', 'da', 'ment', 'do', 'colabor', '.', 'saúd', 'do', 'corpo_telemedicin', '.', 'saúd', 'da', 'mente_', 'telepsicolog', '.', 'nutr', '.', 'jorn', 'de', 'trabalh', ':', 'segund', 'a', 'sexta-f', '|', 'hor', 'padr', ':', '8h30', 'às', '17h30', 'modal', 'de', 'trabalh', ':', 'presenc', ',', 'com', '1', 'dia', 'flex', '-', 'hom', 'offic', 'local', ':', 'far', 'lim', '-', 'são', 'paul']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatization pt-br:  ['EMPRESA', 'Superar', 'expectativa', 'motiva', '!', 'Fornecemos', 'solução', 'logístico', 'completa', ',', 'liderar', 'setor', 'inovação', 'tecnológico', 'configurável', 'fornecer', 'fluxo', 'contínuo', 'informação', 'crescente', 'base', 'cliente', 'verdadeiro', 'visibilidade', 'cadeia', 'suprimento', '.', ' ', 'trabalhar', 'gente', '!', ' ', '(', 'Empresa', ')', 'Lovers', '❤', '️', '🚢', '✈', '️', '🚛', '💼', '📈', '🎯', 'PRINCIPAIS', 'ATIVIDADES', 'Criar', ',', 'manter', 'suporte', 'projeto', 'BI', '.', 'Desenvolver', 'atualizar', 'dashboard', 'relatório', 'Power', 'BI', 'Excel', '.', 'Realizar', 'análises', ',', 'validação', 'tratamento', 'inconsistência', 'dado', '.', 'elaborar', 'relatório', 'gerencial', 'decisão', 'tático', 'estratégico', '.', 'Integrar', 'mesclar', 'dado', 'diferente', 'plataforma', ',', 'banco', 'ferramenta', '.', 'Garantir', 'qualidade', ',', 'padronização', 'governança', 'dado', '.', 'Automatizar', 'processo', 'fluxo', 'Power', 'Automate', 'Python', '.', 'Criar', 'otimizar', 'indicador', 'métrico', 'SQL', 'DAX', '.', 'Apoiar', 'gestor', 'área', 'interpretação', 'dado', 'geração', 'insights', '.', 'REQUISITOS', 'Power', 'BI', '(', 'modelagem', ',', 'dashboard', 'relatório', ')', 'Power', 'Automate', '(', 'fluxos', 'automação', ')', 'SQL', 'SQL', 'Server', '(', 'consulta', ',', 'manipulação', 'integração', 'dado', ')', 'DAX', '(', 'criação', 'medida', 'cálculo', 'Power', 'BI', ')', 'Python', '(', 'tratamento', ',', 'automação', 'análise', 'dado', ')', 'Excel', 'avançar', '(', 'fórmula', ',', 'tabela', 'dinâmico', ',', 'gráfico', ')', 'DIFERENCIAIS', 'Modelagem', 'estruturação', 'banco', 'dado', 'Processos', 'ETL', '(', 'extração', ',', 'transformação', 'carga', ')', 'Governança', 'qualidade', 'dado', 'BENEFÍCIOS', 'COLABORADORES', '🩺', 'seguro', 'Saúde', '🍽', '️', 'Vale-Alimentação', 'Refeição', 'modalidade', 'flex', ',', 'único', 'cartão', '.', '🚌', 'Vale-Transporte', 'COMBO', 'BEM-ESTAR', ':', '🏋', '🏽', '💪', '🏼', '🎧', 'Total', 'Pass', '–', 'conectar', 'colaborador', 'parceiro', 'saúde', 'bem-estar', ',', 'academia', ',', 'estúdio', ',', 'escola', 'dança', 'etc.', '🧠', '💞', '💭', 'C4Life', '–', 'presta', 'suporte', 'colaborador', 'dependente', ',', 'orientação', 'e/ou', 'suporte', 'emocional', ',', 'nossr', 'pilar', ':', 'Psicológico', ',', 'Jurídico', ',', 'Financeiro', ',', 'Social', 'Pets', '.', '𝚿', '🍎', 'clude', '-', 'oferecer', 'solução', 'digital', 'saúde', 'corpo', 'mente', 'colaborador', '.', 'saúde', 'Corpo_Telemedicina', '.', 'Saúde', 'Mente', '_', 'Telepsicologia', '.', 'Nutrição', '.', 'Jornada', 'trabalho', ':', 'sexta-feira', '|', 'Horário', 'padrão', ':', '8h30', '17h30', 'Modalidade', 'trabalho', ':', 'presencial', ',', '1', 'dia', 'flex', '-', 'home', 'office', ' ', ':', 'Faria', 'Lima', '-', 'Paulo']\n"
          ]
        }
      ],
      "source": [
        "# Testando a Stematização\n",
        "porter = nltk.PorterStemmer()\n",
        "print(\"Stemming: \", [porter.stem(i) for i in text])\n",
        "\n",
        "\n",
        "# Agora com um algoritmo para português pt-br\n",
        "from nltk.stem import RSLPStemmer\n",
        "nltk.download('rslp')\n",
        "\n",
        "rlsp = RSLPStemmer()\n",
        "print(\"Stemming pt-br: \", [rlsp.stem(i) for i in text])\n",
        "\n",
        "# Lematização para pt-br agora\n",
        "import spacy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "doc = nlp(raw)\n",
        "print(\"Lemmatization pt-br: \", [i.lemma_ for i in doc if not i.is_stop]) # essa condicional remove as stop words, o que já ajuda a diminuir o tamanho das descrições\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHjmxOAc1VmN"
      },
      "source": [
        "### Conclusão (Módulo de Pré-Processamento Finalizado)\n",
        "\n",
        "O melhor algoritmo para nós será o lematizador do spacy, pois ele é quem funciona para pt-br e manteve a estrutura das palavras melhor.\n",
        "\n",
        "Mas na tokenização vemos que há uma lista de termos que são mais de uma palavra, exemplo: power bi, power automate, SQL Server, Banco de dados, São Paulo, etc. Estes termos são separados como se não fizessem parte de uma coisa só.\n",
        "\n",
        "Para resolvermos isso, precisaremos de um pré-tokenizador: ele irá exrair os termos de uma lista e compará-los com o texto que queremos processar, e, ao encontrá-los, trocar o whitespace por um urderscore.\n",
        "\n",
        "</br>\n",
        "\n",
        "Com este pipeline de pré-processamento validado, a lógica das funções replace_multiword_expressions, preprocess_with_nltk e lemmatize_tokens será extraída deste notebook e implementada como um módulo Python (.py) dentro da arquitetura do backend (src/backend/processing/nlp_utils.py). Isso garantirá que o mesmo tratamento de texto explorado aqui seja aplicado de forma consistente aos dados que entram no banco de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiWoN6W0AWOE"
      },
      "outputs": [],
      "source": [
        "# !pip install -q spacy\n",
        "# !python -m spacy download pt_core_news_sm\n",
        "\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlPS-yN_2Bm5"
      },
      "outputs": [],
      "source": [
        "# queremos diferenciar essas listas para usar a technical_terms no autocomplete do dataentry de skills do frontend.\n",
        "technical_terms = [\"Power BI\", \"Power Automate\", \"Banco de dados\", \"SQL Server\"]\n",
        "locale_terms = [\"São Paulo\"]\n",
        "\n",
        "\n",
        "# Registra cada termo como uma \"special case\" para tokenização, então os termos com palavras compostas serão tradados como unidade, e não divididos. Ex: power bi -> 'power', 'bi'\n",
        "for terms in [technical_terms, locale_terms]:\n",
        "  for term in terms:\n",
        "      nlp.tokenizer.add_special_case(term.lower(), [{ORTH: term.lower()}])\n",
        "\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    lemmas = [\n",
        "        token.lemma_.lower()\n",
        "        for token in doc\n",
        "        if not token.is_stop and not token.is_punct\n",
        "    ]\n",
        "\n",
        "    # Reverte \"_\" para espaços, se quiser manter legibilidade\n",
        "    lemmas = [lemma.replace(\"_\", \" \") for lemma in lemmas]\n",
        "\n",
        "    return \" \".join(lemmas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBaG_B9C-AnN",
        "outputId": "ac3575f9-5587-416a-f378-4bb7e97163bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10789847373962402\n"
          ]
        }
      ],
      "source": [
        "jobs = [\n",
        "    \"SOBRE A EMPRESA Superar expectativas é o que nos motiva! Fornecemos soluções logísticas completas, liderando o setor com inovações tecnológicas configuráveis que fornecem um fluxo contínuo de informações e dão à nossa crescente base de clientes uma verdadeira visibilidade da cadeia de suprimentos.  Vem trabalhar com a gente!  (Empresa) Lovers❤️🚢✈️🚛💼📈🎯 PRINCIPAIS ATIVIDADES Criar, manter e dar suporte a projetos de BI. Desenvolver e atualizar dashboards e relatórios em Power BI e Excel. Realizar análises, validações e tratamento de inconsistências nos dados. Elaborar relatórios gerenciais para decisões táticas e estratégicas. Integrar e mesclar dados de diferentes plataformas, bancos e ferramentas. Garantir a qualidade, padronização e governança dos dados. Automatizar processos e fluxos com Power Automate e Python. Criar e otimizar indicadores e métricas em SQL e DAX. Apoiar gestores e áreas na interpretação de dados e geração de insights. REQUISITOS Power BI (modelagem, dashboards e relatórios) Power Automate (fluxos de automação) SQL e SQL Server (consultas, manipulação e integração de dados) DAX (criação de medidas e cálculos no Power BI) Python (tratamento, automação e análise de dados) Excel avançado (fórmulas, tabelas dinâmicas, gráficos) DIFERENCIAIS Modelagem e estruturação de banco de dados Processos de ETL (extração, transformação e carga) Governança e qualidade de dados BENEFÍCIOS AOS COLABORADORES 🩺 Seguro Saúde 🍽️ Vale-Alimentação e Refeição na modalidade flex, em um único cartão. 🚌 Vale-Transporte COMBO BEM-ESTAR: 🏋🏽💪🏼🎧 Total Pass – conecta o colaborador com parceiros de saúde e bem-estar, como academias, estúdios, escolas de dança etc. 🧠💞💭C4Life – presta suporte aos colaboradores e dependentes, com orientações e/ou suporte emocional, noss pilares: Psicológico, Jurídico, Financeiro, Social e Pets. 𝚿🍎 Clude - oferece soluções digitais para a saúde do corpo da mente dos colaboradores. Saúde do Corpo_Telemedicina. Saúde da Mente_ Telepsicologia. Nutrição. Jornada de trabalho: Segunda a sexta-feira | Horário padrão: 8h30 às 17h30 Modalidade de trabalho: presencial, com 1 dia flex - home office  Local: Faria Lima - São Paulo\",\n",
        "\"\"\n",
        "\n",
        "]\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "for i in jobs:\n",
        "  preprocess_text_spacy(i)\n",
        "\n",
        "print(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOS4WmyER10"
      },
      "source": [
        "## Capítulo 6\n",
        "\n",
        "Baseado neste capítulo, será feito o processamento dos textos (estes já pré-processados) com o algoritmo TF-IDF do scikit-learn\n",
        "\n",
        "Detalhes importantes\n",
        "-\n",
        "\n",
        "- **Limitação do TF-IDF:** Considerando que usaremos o TF-IDF, o IDF fará com que os termos mais frequentes \"percam força\", então faremos uma média ponderada com o TF, para que palavras muito frequentes, tais como Excel, Power BI, e etc ainda se mantenham relevantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a52M5BrXSdHW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\ATIVA\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ativa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.1.0)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
            "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
            "   -------------------------------------- - 8.7/8.9 MB 48.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.9/8.9 MB 30.7 MB/s eta 0:00:00\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl (38.7 MB)\n",
            "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 10.7/38.7 MB 51.7 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 21.0/38.7 MB 51.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 32.2/38.7 MB 51.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  38.5/38.7 MB 51.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.7/38.7 MB 39.7 MB/s eta 0:00:00\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID7fIdTLEUcb"
      },
      "outputs": [],
      "source": [
        "vagas = [\n",
        "    \"analista de dados python sql power bi dashboards relatórios\",\n",
        "    \"desenvolvedor java spring api microsserviços\",\n",
        "    \"cientista de dados python machine learning deep learning\",\n",
        "    \"engenheiro de dados spark hadoop python airflow\"\n",
        "]\n",
        "\n",
        "# treinando os modelos\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=2000) # podemos adicionar um parâmetro 'max_features' para limitar a quantidade de elementos por vetor\n",
        "count = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(vagas) # treinando o tf-idf\n",
        "count_matrix = count.fit_transform(vagas) # treinando o tf apenas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIKt6_vQTrFs",
        "outputId": "2dbd8baa-48f7-44f6-9b4c-f5569f336033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.34488069 0.         0.         0.         0.         0.\n",
            "  0.34488069 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.34488069 0.34488069 0.\n",
            "  0.22013288 0.34488069 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.34488069 0.34488069 0.34488069]]\n"
          ]
        }
      ],
      "source": [
        "# agora devemos fazer o mesmo processo de treinamento do algoritmo, mas com os inputs do usuário. Para o nosso exemplo, vamos supor que seja esta lista:\n",
        "list_user_skills = ['python', 'airflow', 'sql', 'power bi', 'teste', 'dwedw', 'dwdwdw']\n",
        "list_user_skills = ' '.join(list_user_skills)\n",
        "\n",
        "\n",
        "tfidf_user = tfidf.transform([list_user_skills]) # o tfidf do usuário PRECISA estar no mesmo espaço vetorial do algoritmo das vagas.\n",
        "tfidf_user = tfidf.transform([list_user_skills]) \n",
        "\n",
        "print(tfidf_user.toarray())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
